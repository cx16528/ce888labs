{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def translatetorBabiTask(data_path, word_dict):\n",
    "# data initilization\n",
    "    \"\"\"\"\"\n",
    "    __init__\n",
    "        function name: translatetorBabiTask\n",
    "        function: \n",
    "                  translate the natural language dataset into numeric representation of words\n",
    "                  because one story  may have more than one question and one answer\n",
    "                  in this function the story divided by the index of answers\n",
    "                  if the questions in a same story\n",
    "                  put the sentences before current question into current story\n",
    "                  this way can divide the questions in a same story \n",
    "                  and avoid the different answers mapping a same story data (different train_answers map same train_story)\n",
    "                  example a story has 3 question\n",
    "                  the first story data include the first question and sentences before the first question\n",
    "                  the second story data include the second question and sentences before the second question(including the first story)\n",
    "                  the third story data includes the first and second stories\n",
    "                  if there is a new story\n",
    "                  the new story data just include the data in the new story \n",
    "                  the pre-story is not included in the new story data\n",
    "        parameters: \n",
    "                    data_path: the path of dataset\n",
    "                    word_dict: the dictionary of words with numeric representation of words\n",
    "        return: \n",
    "                story: matrix of numeric representation of stories and questions\n",
    "                answers: array of numeric representation of answers\n",
    "        Using data in en/*.txt\n",
    "        Python2.7\n",
    "    \"\"\"\"\"\n",
    "    # define the zeros matrixs of stories and answers\n",
    "    story     = np.zeros((5000, 1000*len(data_path)+1), np.int32)\n",
    "    answers = -np.ones((1000*len(data_path)), np.int32)\n",
    "    # define the index of story, sentence, and answer\n",
    "    story_index    = 0\n",
    "    sentence_index = -1\n",
    "    answer_index = -1\n",
    "\n",
    "    # load the dataset files onebyone\n",
    "    for fi in range(len(data_path)):\n",
    "        f = open(data_path[fi])\n",
    "        # read the dataset sentence-by-sentence\n",
    "        for line in f:  \n",
    "            words = line.split()\n",
    "      \n",
    "            # find the beginning of stories and initialize the index of sentence\n",
    "            if words[0] == '1':\n",
    "                sentence_index = -1\n",
    "\n",
    "            # find the questions sentence\n",
    "            if line.find('?') < 0:\n",
    "                sentence_index += 1\n",
    "            else:\n",
    "                answer_index += 1\n",
    "                sentence_index += 1\n",
    "                story_index  += 1\n",
    "\n",
    "            # put the related pre-story in new story\n",
    "            if sentence_index > 1:\n",
    "                for j in range(0,sentence_index*20):\n",
    "                    story[j-1, story_index] = story[j-1, story_index-1]\n",
    "                    \n",
    "            # translate the words by numeric representation\n",
    "            for k in range(1, len(words)):\n",
    "                w = words[k]\n",
    "                w = w.lower()\n",
    "                if w[len(w)-1] == '.' or w[len(w)-1] == '?':\n",
    "                    w = w[0:len(w)-1]\n",
    "                if not(word_dict.has_key(w)):\n",
    "                    word_dict[w] = len(word_dict)\n",
    "                story[k-1+sentence_index*20, story_index] = word_dict[w]\n",
    "                if words[k][len(words[k])-1] == '?':\n",
    "                    answer = words[k+1]\n",
    "                    answer = answer.lower()\n",
    "                    if not(word_dict.has_key(answer)):\n",
    "                        word_dict[answer] = len(word_dict);\n",
    "                    answers[answer_index] = word_dict[answer]\n",
    "                    break\n",
    "\n",
    "    story     = np.transpose(story[0:(1000*len(data_path)+1), 0:story_index+1])\n",
    "    story = np.delete(story,1000*len(data_path),0)\n",
    "    \n",
    "    return (story, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "# load training datasets.\n",
    "base_dir = 'tasks_1-20_v1-2/en/'\n",
    "train_data_path = [glob(base_dir + 'qa' + str(t) + '_*_train.txt')[0] for t in xrange(1, 21)]\n",
    "word_dict = dict(nil = 0)\n",
    "train_story, train_answers= translatetorBabiTask(train_data_path, word_dict)\n",
    "\n",
    "# load testing datasets.\n",
    "test_data_path = [glob(base_dir + 'qa' + str(t) + '_*_test.txt')[0] for t in xrange(1, 21)]\n",
    "test_story, test_answers = translatetorBabiTask(test_data_path, word_dict)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total accuracy score is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30570000000000003"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# load the train set and test set into random forests\n",
    "# score of random forests module\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "clf.fit(train_story,train_answers)\n",
    "print ('the total accuracy score is')\n",
    "clf.score(test_story, test_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa1_*_test.txt\n",
      "the accuracy score is\n",
      "0.235\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa2_*_test.txt\n",
      "the accuracy score is\n",
      "0.151\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa3_*_test.txt\n",
      "the accuracy score is\n",
      "0.166\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa4_*_test.txt\n",
      "the accuracy score is\n",
      "0.509\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa5_*_test.txt\n",
      "the accuracy score is\n",
      "0.179\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa6_*_test.txt\n",
      "the accuracy score is\n",
      "0.496\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa7_*_test.txt\n",
      "the accuracy score is\n",
      "0.606\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa8_*_test.txt\n",
      "the accuracy score is\n",
      "0.347\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa9_*_test.txt\n",
      "the accuracy score is\n",
      "0.612\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa10_*_test.txt\n",
      "the accuracy score is\n",
      "0.452\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa11_*_test.txt\n",
      "the accuracy score is\n",
      "0.241\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa12_*_test.txt\n",
      "the accuracy score is\n",
      "0.277\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa13_*_test.txt\n",
      "the accuracy score is\n",
      "0.303\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa14_*_test.txt\n",
      "the accuracy score is\n",
      "0.176\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa15_*_test.txt\n",
      "the accuracy score is\n",
      "0.232\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa16_*_test.txt\n",
      "the accuracy score is\n",
      "0.301\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa17_*_test.txt\n",
      "the accuracy score is\n",
      "0.51\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa18_*_test.txt\n",
      "the accuracy score is\n",
      "0.503\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa19_*_test.txt\n",
      "the accuracy score is\n",
      "0.094\n",
      "test dataset\n",
      "tasks_1-20_v1-2/en/qa20_*_test.txt\n",
      "the accuracy score is\n",
      "0.497\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# load training datasets.\n",
    "for n in range(1, 21):\n",
    "    base_dir = 'tasks_1-20_v1-2/en/'\n",
    "    train_data_path = [glob(base_dir + 'qa' + str(t) + '_*_train.txt')[0] for t in xrange(n, n+1)]\n",
    "    word_dict = dict(nil = 0)\n",
    "    train_story, train_answers= translatetorBabiTask(train_data_path, word_dict)\n",
    "\n",
    "# load testing datasets.\n",
    "    test_data_path = [glob(base_dir + 'qa' + str(t) + '_*_test.txt')[0] for t in xrange(n, n+1)]\n",
    "    test_story, test_answers = translatetorBabiTask(test_data_path, word_dict)\n",
    "    clf = RandomForestClassifier(n_estimators = 100)\n",
    "    clf.fit(train_story,train_answers)\n",
    "    score = clf.score(test_story, test_answers)\n",
    "    print ('test dataset')\n",
    "    print (base_dir + 'qa' + str(t) + '_*_test.txt')\n",
    "    print ('the accuracy score is')\n",
    "    print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
